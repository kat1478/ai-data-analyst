# AI Data Analyst

- AI Data Analyst is a production‑oriented tool that automates exploratory data analysis (EDA) and generates a clear, reproducible report. It is designed to demonstrate end‑to‑end data work.

Current status

- Phase 1 — Core analysis: Ready (CLI, Python only).
  - Loads CSVs
  - Detects types and missing values
  - Computes basic statistics
  - Flags simple data issues (high‑missing columns, single‑value columns)
  - Exports a readable report (report.txt)

What I do now (role summary)

- Conduct automated and manual exploratory data analysis (EDA) on tabular datasets.
- Clean and preprocess data: handle missing values, type conversion, basic feature engineering.
- Inspect data quality and flag issues (outliers, columns to drop, suspicious values).
- Produce concise, reproducible reports (text / Markdown / HTML) with key statistics and interpretation.
- Create and save visualizations (histograms, correlation matrices, top categories).
- Build and evaluate simple baseline models (regression/classification) to validate signal.
- Write modular, testable Python code (pandas, numpy, scikit‑learn) and maintain basic unit tests.
- Prepare the project for a lightweight web UI (Streamlit) for demonstrations.

Repository layout

```
ai-data-analyst/
├── README.md
├── data/                 # input CSVs (example.csv)
├── plots/                # (Phase 2) autogenerated plots
├── reports/              # (Phase 2) saved reports/images
├── tests/
│   └── test_main.py
└── src/
    ├── main.py
    └── app.py            # (Phase 3) Streamlit demo
```

Quick start (Phase 1)

1. Create and activate a Python environment (mamba/conda example):

```bash
mamba create -n ai-data python=3.10 -y
mamba activate ai-data
# or using conda:
# conda create -n ai-data python=3.10 -y
# conda activate ai-data
```

2. Install runtime dependencies:

```bash
pip install -r requirements.txt
# or at minimum:
pip install pandas numpy matplotlib seaborn scikit-learn streamlit
```

3. Place your CSV in the `data/` folder (or let the script search recursively).

4. Run the analysis:

```bash
python src/main.py
```

5. Optional: run the Streamlit demo (if app.py is present):

```bash
streamlit run src/app.py
```

Output

- report.txt (project root) — human‑readable EDA summary.
- (Phase 2) charts in plots/ and richer report formats.

Tests

```bash
pip install pytest
pytest
```

Note on dataset (important)

- The synthetic dataset used in this project shows almost no linear relationship between features and Price (very low correlations, negative R² scores). The main goal is to demonstrate a full data analysis and modeling pipeline (EDA, preprocessing, feature engineering, model training, evaluation), not to maximize predictive performance on this specific synthetic data.

Technical stack (v1)

- Python, pandas, numpy, matplotlib / seaborn
- scikit‑learn (for simple models)
- Streamlit (demo UI)
- Report export to plain text / Markdown / HTML in later phases

Roadmap

- Phase 2: Visualizations, richer statistics, improved feature engineering and simple models.
- Phase 3: Lightweight web UI (Streamlit) with file upload and interactive results.
- Phase 4: Polished portfolio deliverable with case study, screenshots and deployment notes.
